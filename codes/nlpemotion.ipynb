{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf ~/.cache/huggingface/hub/models--FacebookAI--xlm-roberta-large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install transformers==4.41.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 0. Environment Setup (Run Once)\n",
    "# -------------------------------\n",
    "!pip uninstall -y peft\n",
    "!pip install transformers==4.41.1 datasets --upgrade\n",
    "\n",
    "# Restart runtime after this cell before running the rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install transformers==4.41.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install --upgrade transformers peft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T12:47:23.050203Z",
     "iopub.status.busy": "2025-10-24T12:47:23.049399Z",
     "iopub.status.idle": "2025-10-24T12:47:26.793259Z",
     "shell.execute_reply": "2025-10-24T12:47:26.792281Z",
     "shell.execute_reply.started": "2025-10-24T12:47:23.050177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T14:00:56.380171Z",
     "iopub.status.busy": "2025-10-24T14:00:56.379605Z",
     "iopub.status.idle": "2025-10-24T14:00:56.384117Z",
     "shell.execute_reply": "2025-10-24T14:00:56.383300Z",
     "shell.execute_reply.started": "2025-10-24T14:00:56.380145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T14:03:01.713486Z",
     "iopub.status.busy": "2025-10-24T14:03:01.712903Z",
     "iopub.status.idle": "2025-10-24T15:15:26.450572Z",
     "shell.execute_reply": "2025-10-24T15:15:26.449210Z",
     "shell.execute_reply.started": "2025-10-24T14:03:01.713460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training xlm-roberta-base =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09613dac1e4a628a2141f7c705b979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6658f7982141a3afa094dc76ef68da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc8f66fa575411b97ccb227438d5d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6782c9b8242445ac9ae68a0967d77f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13594058574f414297bc223277e9704d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30090794a5ec48708d79ba87df11798d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da0c78731b3427f9737df117635441e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ce9958c6994b1a8e58b2bbae5fd473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7299' max='7299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7299/7299 48:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.687400</td>\n",
       "      <td>0.631548</td>\n",
       "      <td>0.763666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.592032</td>\n",
       "      <td>0.776819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.644592</td>\n",
       "      <td>0.782573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ xlm-roberta-base Accuracy: 0.7855\n",
      "Confusion Matrix:\n",
      "[[  16    0    1    9   12]\n",
      " [   4    0    0    5    3]\n",
      " [   2    0  278  114    6]\n",
      " [   4    0  106 1245  117]\n",
      " [  11    0   20  108  373]]\n",
      "\n",
      "\n",
      "===== Training distilbert-base-multilingual-cased =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91ef87bb3b94a4f8ec022b5f6ec566c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f1dcf00be343ecaabea42e0618363f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454e7867e4274e6c822285756b2af1bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7299' max='7299' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7299/7299 22:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.751100</td>\n",
       "      <td>0.710760</td>\n",
       "      <td>0.728730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.663926</td>\n",
       "      <td>0.752569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.702256</td>\n",
       "      <td>0.761200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ distilbert-base-multilingual-cased Accuracy: 0.7457\n",
      "Confusion Matrix:\n",
      "[[   8    0    2   11   17]\n",
      " [   2    3    0    6    1]\n",
      " [   4    0  219  153   24]\n",
      " [   2    0   99 1250  121]\n",
      " [   7    2   21  147  335]]\n",
      "\n",
      "\n",
      "===== Training sentence-transformers/indic-bert =====\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "sentence-transformers/indic-bert is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/sentence-transformers/indic-bert/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1008\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# Unauthorized => likely a token issue => let's raise the actual error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mhead_call_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1542\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1544\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    451\u001b[0m             )\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-68fb980e-0c1ccabd58ceb99d1b989e24;e4fad12c-ae0e-4a5a-8fb3-1958c734d3d5)\n\nRepository Not Found for url: https://huggingface.co/sentence-transformers/indic-bert/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_106/2647547435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mmodel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mmodel_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_106/2647547435.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_name, batch_size, fp16)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    816\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We cannot recover from them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGatedRepoError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             raise OSError(\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0;34mf\"{path_or_repo_id} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: sentence-transformers/indic-bert is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# NLP Project: Emotion Classification (Kaggle-ready)\n",
    "# GPU-safe version\n",
    "# =============================\n",
    "\n",
    "!pip install -q transformers datasets scikit-learn torch\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Dataset\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"/kaggle/input/nlpdataset1/train.csv\")[['Sentence', 'Emotion']]\n",
    "val_df = pd.read_csv(\"/kaggle/input/nlpdataset1/val.csv\")[['Sentence', 'Emotion']]\n",
    "test_df = pd.read_csv(\"/kaggle/input/nlpdataset1/test.csv\")[['Sentence', 'Emotion']]\n",
    "\n",
    "# Encode Emotion labels\n",
    "le = LabelEncoder()\n",
    "train_df['Emotion'] = le.fit_transform(train_df['Emotion'])\n",
    "val_df['Emotion'] = le.transform(val_df['Emotion'])\n",
    "test_df['Emotion'] = le.transform(test_df['Emotion'])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Model Selection (GPU-safe)\n",
    "# -----------------------------\n",
    "model_names = [\n",
    "    \"xlm-roberta-base\",  # smaller than large\n",
    "    \"distilbert-base-multilingual-cased\",\n",
    "    \"sentence-transformers/indic-bert\",\n",
    "    \"bert-base-multilingual-cased\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Tokenization Function\n",
    "# -----------------------------\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"Sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Train Function\n",
    "# -----------------------------\n",
    "def train_model(model_name, batch_size=4, fp16=True):\n",
    "    print(f\"\\n===== Training {model_name} =====\")\n",
    "    \n",
    "    # Clear GPU cache before starting\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    \n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_val = val_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_test = test_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    \n",
    "    # Rename label column for Trainer\n",
    "    tokenized_train = tokenized_train.rename_column(\"Emotion\", \"labels\")\n",
    "    tokenized_val = tokenized_val.rename_column(\"Emotion\", \"labels\")\n",
    "    tokenized_test = tokenized_test.rename_column(\"Emotion\", \"labels\")\n",
    "    \n",
    "    # Set format for PyTorch\n",
    "    tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name.replace('/', '_')}\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=False,\n",
    "        fp16=fp16  # mixed precision\n",
    "    )\n",
    "    \n",
    "    # Metrics function\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        return {\"accuracy\": acc}\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Predict on test set\n",
    "    preds_output = trainer.predict(tokenized_test)\n",
    "    preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "    \n",
    "    # Confusion matrix & classification report\n",
    "    cm = confusion_matrix(test_df['Emotion'], preds)\n",
    "    report = classification_report(test_df['Emotion'], preds, target_names=le.classes_, output_dict=True)\n",
    "    acc = accuracy_score(test_df['Emotion'], preds)\n",
    "    \n",
    "    # Delete model to free memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"✅ {model_name} Accuracy: {acc:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"preds\": preds,\n",
    "        \"cm\": cm,\n",
    "        \"report\": report,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Train All Models\n",
    "# -----------------------------\n",
    "model_results = []\n",
    "for model_name in model_names:\n",
    "    res = train_model(model_name, batch_size=4, fp16=True)\n",
    "    model_results.append(res)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Stacking Ensemble (Majority Voting)\n",
    "# -----------------------------\n",
    "all_preds = np.array([res['preds'] for res in model_results])\n",
    "stacked_preds = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_preds)\n",
    "stacked_cm = confusion_matrix(test_df['Emotion'], stacked_preds)\n",
    "stacked_report = classification_report(test_df['Emotion'], stacked_preds, target_names=le.classes_, output_dict=True)\n",
    "stacked_acc = accuracy_score(test_df['Emotion'], stacked_preds)\n",
    "\n",
    "stacked_result = {\n",
    "    \"model_name\": \"Stacked_Ensemble\",\n",
    "    \"preds\": stacked_preds,\n",
    "    \"cm\": stacked_cm,\n",
    "    \"report\": stacked_report,\n",
    "    \"accuracy\": stacked_acc\n",
    "}\n",
    "\n",
    "print(f\"✅ Stacked Ensemble Accuracy: {stacked_acc:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{stacked_cm}\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Save Results in Pickle\n",
    "# -----------------------------\n",
    "all_results = {\n",
    "    \"label_encoder\": le,\n",
    "    \"individual_model_results\": model_results,\n",
    "    \"stacked_result\": stacked_result\n",
    "}\n",
    "\n",
    "with open(\"emotion_model_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)\n",
    "\n",
    "print(\"✅ Training complete! Results saved to emotion_model_results.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xlm-roberta-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T17:30:35.389926Z",
     "iopub.status.busy": "2025-10-24T17:30:35.389568Z",
     "iopub.status.idle": "2025-10-24T17:30:35.426259Z",
     "shell.execute_reply": "2025-10-24T17:30:35.425355Z",
     "shell.execute_reply.started": "2025-10-24T17:30:35.389892Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry      0.432     0.421     0.427        38\n",
      "        fear      0.000     0.000     0.000        12\n",
      "       happy      0.686     0.695     0.691       400\n",
      "          no      0.841     0.846     0.843      1472\n",
      "         sad      0.730     0.729     0.729       512\n",
      "\n",
      "    accuracy                          0.786      2434\n",
      "   macro avg      0.538     0.538     0.538      2434\n",
      "weighted avg      0.781     0.786     0.784      2434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Confusion matrix\n",
    "cm = np.array([\n",
    "    [16, 0, 1, 9, 12],\n",
    "    [4, 0, 0, 5, 3],\n",
    "    [2, 0, 278, 114, 6],\n",
    "    [4, 0, 106, 1245, 117],\n",
    "    [11, 0, 20, 108, 373]\n",
    "])\n",
    "\n",
    "# Class labels\n",
    "labels = [\"angry\", \"fear\", \"happy\", \"no\", \"sad\"]\n",
    "\n",
    "# Derive predictions and true labels from confusion matrix\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(cm)):\n",
    "    for j in range(len(cm)):\n",
    "        y_true += [labels[i]] * cm[i, j]\n",
    "        y_pred += [labels[j]] * cm[i, j]\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred, target_names=labels, digits=3)\n",
    "print(\"Classification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T15:36:41.770917Z",
     "iopub.status.busy": "2025-10-24T15:36:41.770592Z",
     "iopub.status.idle": "2025-10-24T15:57:18.963406Z",
     "shell.execute_reply": "2025-10-24T15:57:18.962576Z",
     "shell.execute_reply.started": "2025-10-24T15:36:41.770894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training ai4bharat/IndicBERTv2-SS =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b01baf147ba46e68287e301aa098242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f8fb97269a46b98238c47e1302f4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/6.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcec1612dae40d7914e5e4543a57bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f437b8c20148a5a75d65115a863461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/639 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2662222284d54a8aa57dc3512aaecf67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e48bd3a1c6f4373ac832d4b322abb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/IndicBERTv2-SS and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a67e5365464d0d8170bf34047d04b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c28bbe29d549bba9a2cbc4aa502a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f07e4ebb74412fbcec223184b97c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1827' max='1827' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1827/1827 19:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.956900</td>\n",
       "      <td>0.970157</td>\n",
       "      <td>0.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.911700</td>\n",
       "      <td>0.912590</td>\n",
       "      <td>0.638718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.879578</td>\n",
       "      <td>0.648582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[   0    0    1   22   15]\n",
      " [   0    0    0    9    3]\n",
      " [   0    0   71  283   46]\n",
      " [   0    0   51 1300  121]\n",
      " [   0    0   17  276  219]]\n",
      "\n",
      "Accuracy: 0.6532456861133936\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "angry          0.000000  0.000000  0.000000    38.000000\n",
      "fear           0.000000  0.000000  0.000000    12.000000\n",
      "happy          0.507143  0.177500  0.262963   400.000000\n",
      "no             0.687831  0.883152  0.773349  1472.000000\n",
      "sad            0.542079  0.427734  0.478166   512.000000\n",
      "accuracy       0.653246  0.653246  0.653246     0.653246\n",
      "macro avg      0.347411  0.297677  0.302896  2434.000000\n",
      "weighted avg   0.613348  0.653246  0.611494  2434.000000\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets scikit-learn torch\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Dataset\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"/kaggle/input/nlpdataset1/train.csv\")[['Sentence', 'Emotion']]\n",
    "val_df = pd.read_csv(\"/kaggle/input/nlpdataset1/val.csv\")[['Sentence', 'Emotion']]\n",
    "test_df = pd.read_csv(\"/kaggle/input/nlpdataset1/test.csv\")[['Sentence', 'Emotion']]\n",
    "\n",
    "# Encode Emotion labels\n",
    "le = LabelEncoder()\n",
    "train_df['Emotion'] = le.fit_transform(train_df['Emotion'])\n",
    "val_df['Emotion'] = le.transform(val_df['Emotion'])\n",
    "test_df['Emotion'] = le.transform(test_df['Emotion'])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Tokenization Function\n",
    "# -----------------------------\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"Sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train Function for Third Model\n",
    "# -----------------------------\n",
    "def train_third_model(model_name=\"ai4bharat/IndicBERTv2-SS\"):\n",
    "    print(f\"\\n===== Training {model_name} =====\")\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # ✅ Handle multi-GPU safely\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel...\")\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_val = val_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_test = test_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "\n",
    "    # Rename label column for Trainer\n",
    "    tokenized_train = tokenized_train.rename_column(\"Emotion\", \"labels\")\n",
    "    tokenized_val = tokenized_val.rename_column(\"Emotion\", \"labels\")\n",
    "    tokenized_test = tokenized_test.rename_column(\"Emotion\", \"labels\")\n",
    "\n",
    "    # Set format for PyTorch\n",
    "    tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training arguments (FIXED)\n",
    "    # -----------------------------\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name.replace('/', '_')}\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=False,\n",
    "        remove_unused_columns=False  # ✅ FIX FOR THE ERROR\n",
    "    )\n",
    "\n",
    "    # Metrics function\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        return {\"accuracy\": acc}\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Predict on test set\n",
    "    preds_output = trainer.predict(tokenized_test)\n",
    "    preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "    # Confusion matrix & classification report\n",
    "    cm = confusion_matrix(test_df['Emotion'], preds)\n",
    "    report = classification_report(test_df['Emotion'], preds, target_names=le.classes_, output_dict=True)\n",
    "    acc = accuracy_score(test_df['Emotion'], preds)\n",
    "\n",
    "    # Save results\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"model\": model,\n",
    "        \"preds\": preds,\n",
    "        \"cm\": cm,\n",
    "        \"report\": report,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "    with open(\"third_model_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"\\nAccuracy: {acc}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Run Training\n",
    "# -----------------------------\n",
    "third_model_results = train_third_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T17:10:54.633406Z",
     "iopub.status.busy": "2025-10-24T17:10:54.632438Z",
     "iopub.status.idle": "2025-10-24T17:27:42.409736Z",
     "shell.execute_reply": "2025-10-24T17:27:42.408931Z",
     "shell.execute_reply.started": "2025-10-24T17:10:54.633367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training bert-base-multilingual-cased =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a65c572444b4f23ba425e732db8c9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19464 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84d9a15d29849f7a286fa29a485511b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2433 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55beb26ed4754dafb2c6de6a6f1b0bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2434 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1827' max='1827' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1827/1827 16:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.676383</td>\n",
       "      <td>0.747637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.609900</td>\n",
       "      <td>0.612836</td>\n",
       "      <td>0.766543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.620043</td>\n",
       "      <td>0.772298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[   8    0    3    9   18]\n",
      " [   2    3    0    4    3]\n",
      " [   3    0  233  143   21]\n",
      " [   0    0   99 1254  119]\n",
      " [   9    3   34  121  345]]\n",
      "\n",
      "Accuracy: 0.7571898110106821\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score     support\n",
      "angry          0.363636  0.210526  0.266667    38.00000\n",
      "fear           0.500000  0.250000  0.333333    12.00000\n",
      "happy          0.631436  0.582500  0.605982   400.00000\n",
      "no             0.819073  0.851902  0.835165  1472.00000\n",
      "sad            0.681818  0.673828  0.677800   512.00000\n",
      "accuracy       0.757190  0.757190  0.757190     0.75719\n",
      "macro avg      0.599193  0.513751  0.543789  2434.00000\n",
      "weighted avg   0.750681  0.757190  0.753049  2434.00000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pickle\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Dataset\n",
    "# -----------------------------\n",
    "train_df = pd.read_csv(\"/kaggle/input/nlpdataset1/train.csv\")[['Sentence', 'Emotion']]\n",
    "val_df = pd.read_csv(\"/kaggle/input/nlpdataset1/val.csv\")[['Sentence', 'Emotion']]\n",
    "test_df = pd.read_csv(\"/kaggle/input/nlpdataset1/test.csv\")[['Sentence', 'Emotion']]\n",
    "\n",
    "# Encode Emotion labels\n",
    "le = LabelEncoder()\n",
    "train_df['Emotion'] = le.fit_transform(train_df['Emotion'])\n",
    "val_df['Emotion'] = le.transform(val_df['Emotion'])\n",
    "test_df['Emotion'] = le.transform(test_df['Emotion'])\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Tokenization Function\n",
    "# -----------------------------\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"Sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Train Function for Fourth Model\n",
    "# -----------------------------\n",
    "def train_fourth_model(model_name=\"bert-base-multilingual-cased\"):\n",
    "    print(f\"\\n===== Training {model_name} =====\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # Tokenize datasets\n",
    "    tokenized_train = train_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_val = val_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "    tokenized_test = test_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
    "\n",
    "    # Rename label column for Trainer\n",
    "    tokenized_train = tokenized_train.rename_column(\"Emotion\", \"labels\")\n",
    "    tokenized_val = tokenized_val.rename_column(\"Emotion\", \"labels\")\n",
    "    tokenized_test = tokenized_test.rename_column(\"Emotion\", \"labels\")\n",
    "\n",
    "    # Set format for PyTorch\n",
    "    tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "    tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results_{model_name.replace('/', '_')}\",\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=False,\n",
    "        fp16=True  # enable mixed precision for speed\n",
    "    )\n",
    "\n",
    "    # Metrics function\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        return {\"accuracy\": acc}\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    trainer.train()\n",
    "\n",
    "    # Predict on test set\n",
    "    preds_output = trainer.predict(tokenized_test)\n",
    "    preds = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "    # Confusion matrix & classification report\n",
    "    cm = confusion_matrix(test_df['Emotion'], preds)\n",
    "    report = classification_report(test_df['Emotion'], preds, target_names=le.classes_, output_dict=True)\n",
    "    acc = accuracy_score(test_df['Emotion'], preds)\n",
    "\n",
    "    # Save to pickle\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"tokenizer\": tokenizer,\n",
    "        \"model\": model,\n",
    "        \"preds\": preds,\n",
    "        \"cm\": cm,\n",
    "        \"report\": report,\n",
    "        \"accuracy\": acc\n",
    "    }\n",
    "\n",
    "    with open(\"fourth_model_results.pkl\", \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "    # Print outputs\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"\\nAccuracy: {acc}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Run Training\n",
    "# -----------------------------\n",
    "bertbase = train_fourth_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8560904,
     "sourceId": 13484310,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
