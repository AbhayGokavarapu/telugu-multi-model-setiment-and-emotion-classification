{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13601005,"sourceType":"datasetVersion","datasetId":8642668},{"sourceId":13601572,"sourceType":"datasetVersion","datasetId":8643093}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# NLP Project: Emotion Classification (XLM-RoBERTa only)\n# Kaggle-ready + GPU-safe\n# =============================\n\n!pip install -q transformers datasets scikit-learn torch\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nimport pandas as pd\nimport torch\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom datasets import Dataset\nimport pickle\n\n# -----------------------------\n# 1. Load Dataset (Updated paths)\n# -----------------------------\ntrain_df = pd.read_csv(\"/kaggle/input/nlpwadernew/final_vader_filtered (1).csv\")[['Sentence', 'Emotion']]\nval_df = pd.read_csv(\"/kaggle/input/nlpwadernew/val.csv\")[['Sentence', 'Emotion']]\ntest_df = pd.read_csv(\"/kaggle/input/nlpwadernew/test.csv\")[['Sentence', 'Emotion']]\n\n# Encode Emotion labels\nle = LabelEncoder()\ntrain_df['Emotion'] = le.fit_transform(train_df['Emotion'])\nval_df['Emotion'] = le.transform(val_df['Emotion'])\ntest_df['Emotion'] = le.transform(test_df['Emotion'])\nnum_labels = len(le.classes_)\n\n# Convert to HuggingFace Dataset\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n# -----------------------------\n# 2. Model Selection\n# -----------------------------\nmodel_name = \"xlm-roberta-base\"\n\n# -----------------------------\n# 3. Tokenization Function\n# -----------------------------\ndef tokenize_function(examples, tokenizer):\n    return tokenizer(examples[\"Sentence\"], padding=\"max_length\", truncation=True, max_length=128)\n\n# -----------------------------\n# 4. Train Function\n# -----------------------------\ndef train_model(model_name, batch_size=4, fp16=True):\n    print(f\"\\n===== Training {model_name} =====\")\n    \n    torch.cuda.empty_cache()\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n    \n    # Tokenize datasets\n    tokenized_train = train_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n    tokenized_val = val_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n    tokenized_test = test_dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n    \n    # Rename label column for Trainer\n    tokenized_train = tokenized_train.rename_column(\"Emotion\", \"labels\")\n    tokenized_val = tokenized_val.rename_column(\"Emotion\", \"labels\")\n    tokenized_test = tokenized_test.rename_column(\"Emotion\", \"labels\")\n    \n    # Set format for PyTorch\n    tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n    tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n    tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=f\"./results_{model_name.replace('/', '_')}\",\n        num_train_epochs=3,\n        per_device_train_batch_size=batch_size,\n        per_device_eval_batch_size=batch_size,\n        learning_rate=2e-5,\n        weight_decay=0.01,\n        eval_strategy=\"epoch\",\n        save_strategy=\"no\",\n        logging_strategy=\"steps\",\n        logging_steps=50,\n        report_to=\"none\",\n        fp16=fp16\n    )\n    \n    # Metrics function\n    def compute_metrics(eval_pred):\n        logits, labels = eval_pred\n        predictions = np.argmax(logits, axis=-1)\n        acc = accuracy_score(labels, predictions)\n        return {\"accuracy\": acc}\n    \n    # Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train,\n        eval_dataset=tokenized_val,\n        compute_metrics=compute_metrics\n    )\n    \n    # Train\n    trainer.train()\n    \n    # Predict on test set\n    preds_output = trainer.predict(tokenized_test)\n    preds = np.argmax(preds_output.predictions, axis=-1)\n    \n    # Metrics\n    cm = confusion_matrix(test_df['Emotion'], preds)\n    report = classification_report(test_df['Emotion'], preds, target_names=le.classes_, output_dict=True)\n    acc = accuracy_score(test_df['Emotion'], preds)\n    \n    print(f\"âœ… {model_name} Accuracy: {acc:.4f}\")\n    print(f\"Confusion Matrix:\\n{cm}\\n\")\n    \n    return {\n        \"model_name\": model_name,\n        \"tokenizer\": tokenizer,\n        \"preds\": preds,\n        \"cm\": cm,\n        \"report\": report,\n        \"accuracy\": acc\n    }\n\n# -----------------------------\n# 5. Train Only XLM-RoBERTa\n# -----------------------------\nresult = train_model(model_name, batch_size=4, fp16=True)\n\n# -----------------------------\n# 6. Save Results\n# -----------------------------\nall_results = {\n    \"label_encoder\": le,\n    \"model_result\": result\n}\n\nwith open(\"emotion_xlm_roberta_results.pkl\", \"wb\") as f:\n    pickle.dump(all_results, f)\n\nprint(\"âœ… Training complete! Results saved to emotion_xlm_roberta_results.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T16:59:42.016723Z","iopub.execute_input":"2025-11-03T16:59:42.017026Z","iopub.status.idle":"2025-11-03T17:54:28.920328Z","shell.execute_reply.started":"2025-11-03T16:59:42.017001Z","shell.execute_reply":"2025-11-03T17:54:28.919601Z"}},"outputs":[{"name":"stdout","text":"\n===== Training xlm-roberta-base =====\n","output_type":"stream"},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/21202 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a5d3bb55b6d4633a21f83601cbc9850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2433 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc89940656654035a2eb0a3f697fb0fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2434 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a855614e5a547ca86bb0a9ce08e44f6"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7953' max='7953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7953/7953 53:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.632500</td>\n      <td>0.717185</td>\n      <td>0.719688</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.608100</td>\n      <td>0.723329</td>\n      <td>0.743527</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.448500</td>\n      <td>0.781406</td>\n      <td>0.737361</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"âœ… xlm-roberta-base Accuracy: 0.7391\nConfusion Matrix:\n[[  17    0    1    9   11]\n [   2    4    0    4    2]\n [   4    0  287   93   16]\n [   5    0  197 1090  180]\n [   9    2   15   85  401]]\n\nâœ… Training complete! Results saved to emotion_xlm_roberta_results.pkl\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pickle\nimport pandas as pd\n\n# Load the results\nwith open(\"/kaggle/input/pklxlm/emotion_xlm_roberta_results.pkl\", \"rb\") as f:\n    results = pickle.load(f)\n\n# Extract model result\nmodel_result = results[\"model_result\"]\n\n# Get confusion matrix and classification report\ncm = model_result[\"cm\"]\nreport_dict = model_result[\"report\"]\naccuracy = model_result[\"accuracy\"]\nmodel_name = model_result[\"model_name\"]\n\n# Display Confusion Matrix\nprint(\"âœ… Model:\", model_name)\nprint(f\"Overall Accuracy: {accuracy:.4f}\\n\")\nprint(\"ðŸ”¹ Confusion Matrix:\")\nprint(pd.DataFrame(cm))\n\n# Display Classification Report (nicely formatted)\nprint(\"\\nðŸ”¹ Classification Report:\")\nreport_df = pd.DataFrame(report_dict).transpose()\nprint(report_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T17:59:54.311583Z","iopub.execute_input":"2025-11-03T17:59:54.312134Z","iopub.status.idle":"2025-11-03T17:59:55.268502Z","shell.execute_reply.started":"2025-11-03T17:59:54.312109Z","shell.execute_reply":"2025-11-03T17:59:55.267487Z"}},"outputs":[{"name":"stdout","text":"âœ… Model: xlm-roberta-base\nOverall Accuracy: 0.7391\n\nðŸ”¹ Confusion Matrix:\n    0  1    2     3    4\n0  17  0    1     9   11\n1   2  4    0     4    2\n2   4  0  287    93   16\n3   5  0  197  1090  180\n4   9  2   15    85  401\n\nðŸ”¹ Classification Report:\n              precision    recall  f1-score      support\nangry          0.459459  0.447368  0.453333    38.000000\nfear           0.666667  0.333333  0.444444    12.000000\nhappy          0.574000  0.717500  0.637778   400.000000\nno             0.850898  0.740489  0.791863  1472.000000\nsad            0.657377  0.783203  0.714795   512.000000\naccuracy       0.739113  0.739113  0.739113     0.739113\nmacro avg      0.641680  0.604379  0.608443  2434.000000\nweighted avg   0.757666  0.739113  0.743332  2434.000000\n","output_type":"stream"}],"execution_count":6}]}